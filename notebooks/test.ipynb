{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\an2fe\\anaconda3\\envs\\mlmodels\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_loc(df, index, columns, val):\n",
    "    \"\"\" Insert data in a DataFrame with SparseDtype format\n",
    "\n",
    "    Only applicable for pandas version > 0.25\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    df : DataFrame with series formatted with pd.SparseDtype\n",
    "    index: str, or list, or slice object\n",
    "        Same as one would use as first argument of .loc[]\n",
    "    columns: str, list, or slice\n",
    "        Same one would normally use as second argument of .loc[]\n",
    "    val: insert values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: DataFrame\n",
    "        Modified DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the original sparse format for reuse later\n",
    "    spdtypes = df.dtypes[columns]\n",
    "\n",
    "    # Convert concerned Series to dense format\n",
    "    df[columns] = df[columns].sparse.to_dense()\n",
    "\n",
    "    # Ensures the order of the columns is the same\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    val = val.reindex(sorted(val.columns), axis=1)\n",
    "    val_list = val.values.tolist()\n",
    "    \n",
    "    # Do a normal insertion with .loc[]\n",
    "    df.loc[index, columns] = val_list\n",
    "\n",
    "    # Back to the original sparse format\n",
    "    df[columns] = df[columns].astype(spdtypes)\n",
    "\n",
    "    return df\n",
    "\n",
    "def one_hot_encoding_predict(df, info):\n",
    "    cat_cols = info['cat_cols']\n",
    "    df_cat = df[cat_cols]\n",
    "    df_cat[pd.isnull(df_cat)]  = 'NaN'\n",
    "    \n",
    "    num_cols = [c for c in df.columns if c not in cat_cols]\n",
    "\n",
    "    ln_df = len(df)\n",
    "    for cat in cat_cols:\n",
    "        single_cat_cols = info[cat].columns\n",
    "        zr = np.zeros((ln_df,len(single_cat_cols)))\n",
    "        oh_df = pd.DataFrame(zr, columns = single_cat_cols)\n",
    "        print(oh_df)\n",
    "    # enc = preprocessing.OneHotEncoder()\n",
    "    # enc.fit(df_cat)\n",
    "    # onehotlabels = enc.transform(df_cat)\n",
    "    # # transformed_df = pd.DataFrame(onehotlabels, columns=enc.get_feature_names_out())\n",
    "    # transformed_df = pd.DataFrame.sparse.from_spmatrix(onehotlabels, columns=enc.get_feature_names_out(), index=df_cat.index)\n",
    "\n",
    "    # # Replace nans for distribution\n",
    "    # for cat in cat_cols:\n",
    "    #     oh_name = [x for x in transformed_df.columns if cat in x and 'NaN' not in x]\n",
    "    #     # nan_df = pd.DataFrame(columns=oh_name)\n",
    "    #     counts = df[cat].dropna().groupby(df[cat].dropna()).count()\n",
    "    #     percentage = counts/len(counts)\n",
    "    #     percentage_df = pd.DataFrame(percentage).transpose()\n",
    "    #     percentage_df = percentage_df.add_prefix(cat + '_')\n",
    "    #     print(oh_name)\n",
    "    #     transformed_df = sp_loc(transformed_df, transformed_df[cat + '_NaN'] == 1.0, oh_name, percentage_df)\n",
    "    #     transformed_df = transformed_df.drop([cat + '_NaN'], axis = 1)\n",
    "    # return pd.concat([df[num_cols],transformed_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\", index_col='id')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessing information\n",
    "info = joblib.load(\"../data/preproc_info.pkl\")\n",
    "data_cols = joblib.load(\"../data/data_cols.pkl\")\n",
    "target_col = joblib.load(\"../data/target_col.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keyword_ablaze', 'keyword_accident', 'keyword_aftershock',\n",
       "       'keyword_airplane_accident', 'keyword_ambulance', 'keyword_annihilated',\n",
       "       'keyword_annihilation', 'keyword_apocalypse', 'keyword_armageddon',\n",
       "       'keyword_army',\n",
       "       ...\n",
       "       'keyword_weapons', 'keyword_whirlwind', 'keyword_wild_fires',\n",
       "       'keyword_wildfire', 'keyword_windstorm', 'keyword_wounded',\n",
       "       'keyword_wounds', 'keyword_wreck', 'keyword_wreckage',\n",
       "       'keyword_wrecked'],\n",
       "      dtype='object', name='keyword', length=221)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['keyword'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
